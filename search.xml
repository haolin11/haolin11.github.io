<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>第一篇文章</title>
      <link href="/2022/12/03/Online-Temporal-Calibration-for-Monocular-Visual-Inertial-Systems/"/>
      <url>/2022/12/03/Online-Temporal-Calibration-for-Monocular-Visual-Inertial-Systems/</url>
      
        <content type="html"><![CDATA[<h1 id="Online-Temporal-Calibration-for-Monocular-Visual-Inertial-Systems"><a href="#Online-Temporal-Calibration-for-Monocular-Visual-Inertial-Systems" class="headerlink" title="Online Temporal Calibration for Monocular Visual-Inertial Systems"></a>Online Temporal Calibration for Monocular Visual-Inertial Systems</h1><p><strong>DOI:</strong> <a href="https://doi.org/10.1109/IROS.2018.8593603">10.1109&#x2F;IROS.2018.8593603</a></p><h2 id="基础知识"><a href="#基础知识" class="headerlink" title="基础知识"></a>基础知识</h2><ol><li>摘要：准确的状态估计是机器人导航、自动驾驶、虚拟现实和增强现实等各种智能应用的基础模块。视觉和惯性融合是近年来流行的六自由度状态估计技术。记录不同传感器测量值的时刻对于系统的稳健性和准确性至关重要（<strong>各传感器的时间对齐</strong>）。在实践中，每个传感器的时间戳通常会受到触发和传输延迟的影响，从而导致不同传感器之间的时间错位（时间偏移）。这种时间偏移极大地影响了传感器融合的性能。为此，我们提出了一种在线方法来校准视觉和惯性测量之间的时间偏移。我们的方法通过联合优化时间偏移、相机和 IMU 状态以及 SLAM 系统中的特征位置来实现时间偏移校准。此外，该方法是一个通用模型，可以很容易地在几个基于特征的优化框架中使用。仿真和实验结果表明，即使与其他最先进的离线工具相比，我们的校准方法也具有很高的准确性。 VIO 与其他方法的比较证明，在线时间校准明显有利于视觉惯性系统。</li><li>一方面，惯性测量使俯仰和侧倾角以及尺度变得可观察。另一方面，惯性测量通过在视觉跟踪失败时弥合差距来提高运动跟踪性能。为了融合来自不同传感器的数据，必须精确知道记录测量值的时间点。</li><li>每个传感器的时间戳通常会受到触发和传输延迟的影响，从而导致不同传感器流之间的时间错位（时间偏移）。因此，传感器的时间同步可能会导致多传感器系统的关键问题。对于视觉惯性系统，相机和 IMU 之间的时间偏移会极大地影响鲁棒性和准确性。大多数视觉惯性方法假设测量的时间戳在单个时钟下是精确的，这些方法适用于一些严格硬件同步的传感器。</li><li>对于大多数低成本和自组装传感器组，硬件同步不可用。由于触发和传输延迟，相机和 IMU 之间总是存在时间错位（时间偏移）。时间偏移通常从几毫秒到几百毫秒不等。几十毫秒会导致 IMU 序列与图像流完全错位，从而极大地影响视觉惯性系统的性能。</li><li>为此，我们提出了一种在线校准视觉惯性系统的时间偏移的方法。我们假设时间偏移是一个常数但未知的变量。我们通过在线估计它以及相机和 IMU 状态以及 SLAM 系统中的特征位置来校准它。我们的校准方法是一个通用因子，可以很容易地用于其他基于特征的视觉惯性优化框架。尽管我们使用单目传感器套件来展示我们的方法，但所提出的方法可以很容易地应用于多相机视觉惯性系统。</li><li>我们的贡献如下： <ul><li>我们提出了一种在线校准视觉惯性系统中相机和 IMU 之间时间偏移的方法</li><li>我们通过仿真和真实世界的实验展示了在线时间校准的重要性</li><li>开源代码整合进了开源项目中</li></ul></li><li>时间偏移：<ul><li>对于低成本和自组装视觉惯性传感器，摄像机和惯性测量单元之间没有严格的时间同步。由于触发延迟、传输延迟和非同步时钟，生成的时间戳不等于测量采样时刻的时间。因此，不同传感器测量值之间通常存在时间偏移。</li><li>在一般情况下，传感器之间的时间偏移是一个恒定但未知的值（常数）。在一些更糟糕的情况下，传感器使用不同的时钟进行采集，时间偏移会随时间产生漂移（不是常数），这种传感器不适合传感器融合。在本文中，我们考虑了一般情况，其中时间偏移td是一个常量但未知的值。</li><li>图1中描绘了一幅说明时间偏移的图片。在图中，上半部分表示采样瞬间，下半部分显示了时间戳瞬间。由于触发延迟、传输延迟和时钟不同步，生成的时间戳不等于实际采样时间，从而导致摄像机和IMU之间的时间错位。</li><li>具体来说，我们将td定义为：t<del>IMU</del> &#x3D; t<del>cam</del> + t<del>d</del>  ，其中时间偏移td是我们应该移动摄像机时间戳的时间量，以便摄像机和IMU数据流在时间上保持一致。td可以是正值或负值。如果相机延迟比IMU长，则td为负值。相反，td为正值。</li></ul></li></ol><p><img src="https://gitee.com/haolin12/pixgo_tuchuang/raw/master/img/image-20220702152123847.png" alt="image-20220702152123847"></p><ol start="8"><li>在图像平面的特征速度：<ul><li>为了使相机和IMU数据流在时间上一致，应根据td向前或向后移动相机图像序列。我们没有移动整个摄像机或IMU序列，而是移动特征点的观测值。</li><li>为此，我们引入了用于建模和补偿时间错位的特征速度。在很短的时间内（几毫秒），摄像机的运动可以被视为匀速运动，故图像特征在短时间内在图像平面上也近似匀速移动。基于这个假设，我们计算特征在图像平面上的速度。如图2所示，I<del>k</del>和I<del>k+1</del>是两个连续的图像帧。假设摄像机在短时间内[t<del>k</del>，t<del>k+1</del>]以恒定速度从C^k^移动到C^k+1^。因此，我们近似地认为特征l在这个短时间段内也在图像平面上以恒定速度V<del>l</del>^k^移动。速度V<del>l</del>^k^的计算为像素移动值除以时间间隔t。</li></ul></li></ol><p><img src="https://gitee.com/haolin12/pixgo_tuchuang/raw/master/img/image-20220702173535347.png" alt="image-20220702173535347"></p><ol start="9"><li><p>有时间偏移的视觉因子：</p><ul><li><p>在经典稀疏视觉SLAM算法中，视觉测量表示为代价函数中的（重）投影误差。我们通过添加新变量（时间偏移）来扩展经典（重）投影误差。</p></li><li><p>特征有两种典型的参数化。一些算法将特征参数化为其在全局帧中的三维位置，而其他算法将特征参数化为相对于某个图像坐标系的深度或逆深度。接下来，我们分别在这两种参数化中加入时间偏移。</p></li><li><p>（1）三维位置参数化：特征参数化为全局框架中的三维位置（P<del>l</del>&#x3D;[x<del>l</del>，y<del>l</del>，z<del>l</del>]^T^）。在传统中，视觉测量表示为投影误差，</p><p><img src="https://gitee.com/haolin12/pixgo_tuchuang/raw/master/img/image-20220704091148248.png" alt="image-20220704091148248"></p></li><li><p>z<del>l</del>^k^是对第k帧中特征l的观察。（R<del>ck</del>^w^，p<del>ck</del>^w^）是摄像机位姿，将特征P<del>l</del>从全局坐标系转换为局部摄像机坐标系。π（·）表示摄像机投影模型，该模型将三维特征投影到图像平面，并产生畸变。</p><p><img src="https://gitee.com/haolin12/pixgo_tuchuang/raw/master/img/image-20220704091922829.png" alt="image-20220704091922829"></p><p>（图3描述了重投影过程。虚线表示没有时间偏移建模的传统重投影过程。实线表示考虑了时间偏移的重投影。黄线表示IMU约束。IMU约束与传统的重投影约束不一致。通过优化td，我们可以在时域中找到与IMU约束匹配的最佳摄像机位姿和特征观测。）</p></li><li><p>摄像机位姿（R<del>ck</del>^w^，p<del>ck</del>^w^）受上述公式中视觉测量的约束，它还受到IMU测量的约束。实际上，如果IMU和摄像机之间存在时间错位，则IMU约束与时域中的视觉约束不一致。换句话说，我们应该向前或向后移动摄像机序列，以便摄像机和IMU数据流在时间上保持一致。我们没有移动整个摄像机或IMU序列，而是在时间轴中专门移动特征的观测值。新公式如下：</p><p><img src="https://gitee.com/haolin12/pixgo_tuchuang/raw/master/img/image-20220704105711216.png" alt="image-20220704105711216"></p></li><li><p>V<del>l</del>^k^是特征在图像平面上的速度，由等式2得出。td是时间偏移未知变量，它改变了特征在时域中的观测值。通过优化td，我们可以在时域中找到与IMU约束匹配的最佳摄像机位姿和特征观测。</p></li><li><p>（2）深度参数化：该特征也可以参数化为相对于图像坐标系的深度或逆深度。我们以图像 i 中的深度 λi 为例。从图像 i 到图像 j 的传统重投影误差写为：</p><p><img src="https://gitee.com/haolin12/pixgo_tuchuang/raw/master/img/image-20220704121943301.png" alt="image-20220704121943301"></p></li><li><p>首先将特征l投影到全局帧中，然后将其反投影到局部摄像机帧 j 中的图像平面上。残差是观察和反投影位置之间的偏移。</p></li><li><p>与等式4类似，我们考虑时间偏移变量td到方程中：</p><p><img src="https://gitee.com/haolin12/pixgo_tuchuang/raw/master/img/image-20220704122123247.png" alt="image-20220704122123247"></p></li></ul></li><li><p>带时间偏移的优化：</p><ul><li><p>通过利用上述视觉因子，我们可以轻松地将时间校准函数添加到典型的基于视觉惯性优化的框架中。在这些框架中，视觉惯性SLAM被表述为一个非线性优化问题，将视觉和惯性测量紧密耦合。如图4所示，多个摄像机帧和IMU测量被捆绑为“束”，“束”大小决定计算的时间复杂度。局部束调整（BA）联合优化摄像机和IMU状态以及特征位置。我们可以很容易地将提出的加入时间偏移优化的视觉因子添加到这种框架中。具体而言，整个状态变量增加时间偏移优化量，状态变量定义为：</p><p><img src="https://gitee.com/haolin12/pixgo_tuchuang/raw/master/img/image-20220705090919710.png" alt="image-20220705090919710"></p></li><li><p>其中，第k组预积分的IMU状态由全局坐标系中的位置p<del>k</del>^w^、速度v<del>k</del>^w^、方向R<del>k</del>^w^和局部body坐标系中的IMU偏差b<del>a</del>、b<del>g</del>组成。特征 P<del>l</del> 由全局坐标系中的3D位置或相对于特定图像坐标系的深度参数化。整个问题被表述为一个包含IMU传播因子、重投影因子以及某个先验因子的代价函数。因此，我们使用加入时间偏移变量的视觉因子来实现时间偏移校准，</p><p><img src="https://gitee.com/haolin12/pixgo_tuchuang/raw/master/img/image-20220705090957807.png" alt="image-20220705090957807"></p></li><li><p>e<del>B</del>（z<del>k+1</del>^k^ ，X）是IMU传播的误差项。B是所有IMU测量值的集合。e<del>C</del>（z<del>l</del>^j^ ，X）是提出的包含时间偏移的视觉（重）投影误差，C是在图像帧中观察到至少两次的特征集。误差由其协方差的逆 P 加权。{e<del>p</del>，H<del>p</del>}是来自先验知识和边缘化的先验信息。只有少量测量值和状态保留在优化窗口中，而其他测量值和状态则被边缘化并转换为先验。然后使用高斯-牛顿法高效地优化非线性最小二乘函数。</p></li></ul></li><li><p>时间偏移补偿：</p><ul><li>在每次优化之后，我们通过移动后续视觉流的时间戳来补偿时间偏移，因为t′<del>cam</del>&#x3D;t<del>cam</del>+t<del>d</del>。然后，系统估计补偿视觉测量和惯性测量之间的δ<del>td</del>。δ<del>td</del>将在后续数据流中迭代优化，并收敛到零。随着时间间隔δ<del>t</del>的减小，我们的基本假设（特征在短时间间隔内在图像平面上以恒定速度移动）越来越合理。即使在开始时存在巨大的时间偏移（例如数百毫秒），该过程也会逐渐从粗到细进行补偿，直至收敛到零。</li></ul></li></ol>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
